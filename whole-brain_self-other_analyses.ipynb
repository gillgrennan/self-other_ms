{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81fd053-7a76-4298-a51d-46dee65e87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "from nilearn import image as nimg\n",
    "from nilearn import plotting as nplot\n",
    "import bids\n",
    "from nltools.file_reader import onsets_to_dm\n",
    "from nltools.stats import regress, zscore\n",
    "from nltools.data import Brain_Data, Design_Matrix\n",
    "from nltools.stats import find_spikes \n",
    "from nilearn.plotting import view_img, glass_brain, plot_stat_map\n",
    "from bids import BIDSLayout, BIDSValidator\n",
    "import os\n",
    "from pathlib import Path\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn import plotting\n",
    "from nilearn.plotting import plot_contrast_matrix\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn import plotting\n",
    "# creating mean img for plotting purposes \n",
    "from nilearn.image import mean_img\n",
    "from nilearn.image import load_img\n",
    "from nibabel import load\n",
    "from nibabel.gifti import GiftiDataArray, GiftiImage\n",
    "from nilearn.glm.first_level import run_glm as run_glm\n",
    "from nilearn.glm import compute_contrast\n",
    "import nilearn\n",
    "fsaverage = nilearn.datasets.fetch_surf_fsaverage(mesh='fsaverage')\n",
    "\n",
    "# Making results folder -- change to what this should actually be \n",
    "path = '/Volumes/Seagate Desktop Drive/kdata/'\n",
    "os.chdir(path)\n",
    "output_dir = Path.cwd() / \"results\" / \"surface\" / \"first_level_results\"\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"Output will be saved to: {output_dir}\")\n",
    "\n",
    "#isolating directory called layout_raw (for events.tsv files) -- will change depending on where data is stored / what computer we're running on\n",
    "layout_raw = bids.BIDSLayout('/Volumes/Seagate Desktop Drive/kdata/', validate=True)\n",
    "\n",
    "#isolating directory called layout (for fMRIprep derivatives) -- will change depending on where data is stored / what computer we're running on \n",
    "layout = bids.BIDSLayout('/Volumes/Seagate Desktop Drive/kdata/derivatives', validate=False,\n",
    "                  config=['bids','derivatives'])\n",
    "print(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae7e5f-6dea-46f0-89ea-7a5037cb0fe3",
   "metadata": {},
   "source": [
    "## Subject-wise parameter estimation for self- other- case- and fix \n",
    "creates self-other, self-fix, other-fix, case-fix, self-case contrasts for all subs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6161d7f-bc14-42a9-b536-c4307f195a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for making design matrix \n",
    "# note: keep MNI files for isolating tr / frames bc easier to load \n",
    "def load_bids_events(layout,layout_raw, subject, run, session):\n",
    "    '''Create a design_matrix instance from BIDS event file'''\n",
    "    \n",
    "    tr = 2.5 #put in manually bc get_tr wouldn't work?? \n",
    "    # change lines below -- can change to \"mask\", change task to \"self-other\"\n",
    "    func_files = layout.get(subject=subject,\n",
    "                        datatype='func', task='selfother',session = session,\n",
    "                        desc='preproc',\n",
    "                        space='MNI152NLin2009cAsym',\n",
    "                        extension='nii.gz',\n",
    "                       return_type='file')\n",
    "    func_file = nimg.load_img(func_files[run])\n",
    "    n_tr = func_file.shape[-1]\n",
    "\n",
    "    onsets = pd.read_csv(layout_raw.get(subject=subject, suffix='events', session = session)[run].path)\n",
    "    # line below is isolating the onset, duration, and trial type columns -- change according to events.tsv format \n",
    "    onsets_actual = onsets.iloc[:, [0,1,3]]\n",
    "    onsets_actual.columns = ['onset', 'duration','trial_type'] # make sure this order matches with what's loaded in as \"onsets_actua\n",
    "    sampling_freq = 1/tr\n",
    "    n_scans=n_tr\n",
    "    return onsets_actual, tr, n_scans\n",
    "\n",
    "from nilearn.datasets import fetch_icbm152_brain_gm_mask\n",
    "from nilearn import plotting, masking\n",
    "from nilearn.masking import _unmask_3d\n",
    "from nilearn.maskers import nifti_spheres_masker\n",
    "import nibabel as nib\n",
    "from nibabel import Nifti1Image\n",
    "from nilearn.image import resample_to_img \n",
    "\n",
    "sess = '01'\n",
    "sub = '102'\n",
    "fmri_imgs = layout.get(subject=sub,\n",
    "            datatype='func', task='selfother',session = sess,\n",
    "            desc='preproc',\n",
    "            space='MNI152NLin2009cAsym',\n",
    "            extension='nii.gz',\n",
    "           return_type='file')\n",
    "\n",
    "space_defining_image = masking.compute_brain_mask(fmri_imgs[0])\n",
    "\n",
    "icbm_mask = fetch_icbm152_brain_gm_mask()\n",
    "space_defining_image = masking.compute_brain_mask(fmri_imgs[0])\n",
    "\n",
    "icbm_mask = resample_to_img(source_img=icbm_mask, target_img=space_defining_image, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06bc61-9e67-4f87-9597-a21062ce1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = layout.get_subjects()\n",
    "\n",
    "# subjects missing ses02:\n",
    "# 102, 138, 145, 209, 221, 237 \n",
    "subjects2 = []\n",
    "subjects2 = subjects\n",
    "#subjects2 = subjects\n",
    "#testing second level (removing all subs with errors) \n",
    "del(subjects2[0]) #- 102 \n",
    "del(subjects2[21]) #- 138 +1\n",
    "del(subjects2[25]) #- 145 +1 \n",
    "del(subjects2[32]) #- 209 +1 \n",
    "del(subjects2[40]) #- 221 +1 \n",
    "del(subjects2[50]) #- 237 +2 \n",
    "\n",
    "subjects = layout.get_subjects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791fb4e-1ac9-4fa7-ab65-c6bcc3ddffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to iterate through subjects ... \n",
    "#for sub in subjects \n",
    "from scipy.stats import norm\n",
    "\n",
    "p001_unc = norm.isf(0.001)\n",
    "\n",
    "file_lists = {\"self-other\": list(),\n",
    "    \"other-fix\": list(),\n",
    "     \"self-fix\": list(),\n",
    "     \"case-fix\": list(),\n",
    "     \"self-case\": list()\n",
    "    }\n",
    "\n",
    "firstlevel_plots = {\"self-other\": list(),\n",
    "    \"other-fix\": list(),\n",
    "     \"self-fix\": list(),\n",
    "     \"case-fix\": list(),\n",
    "     \"self-case\": list()                    \n",
    "    }\n",
    "\n",
    "nosessions = ['01','02']\n",
    "\n",
    "for sess in nosessions: \n",
    "\n",
    "    if sess == '01':\n",
    "        subject_list = subjects\n",
    "    elif sess == '02':\n",
    "        subject_list = subjects2\n",
    "    \n",
    "    for sub in subject_list: \n",
    "# change lines below -- can change to \"mask\", change task to \"self-other\" -- should match the same format as in the load_bids_events function\n",
    "        fmri_imgs = layout.get(subject=sub,\n",
    "                    datatype='func', task='selfother',session = sess,\n",
    "                    desc='preproc',\n",
    "                    space='MNI152NLin2009cAsym',\n",
    "                    extension='nii.gz',\n",
    "                   return_type='file')\n",
    "        hrf_model = \"spm\" #canonical hrf \n",
    "        high_pass = 0.01 # The cutoff for the drift model is 0.01 Hz.\n",
    "\n",
    "        confound_files = layout.get(subject=sub,\n",
    "                        datatype='func', task='selfother',session = sess,\n",
    "                        desc='confounds',\n",
    "                       extension=\"tsv\",\n",
    "                       return_type='file')\n",
    "\n",
    "# Select confounds -- set right now to just the 6 motion parameters but can add in more/less! \n",
    "       #32 confound_vars -- REMOVING GLOBAL SIGNAL \n",
    "        confound_vars = ['trans_x','trans_x_derivative1','trans_x_derivative1_power2','trans_x_power2',\n",
    "                           'trans_y','trans_y_derivative1','trans_y_derivative1_power2','trans_y_power2',\n",
    "                             'trans_z','trans_z_derivative1','trans_z_derivative1_power2','trans_z_power2',\n",
    "                             'rot_x','rot_x_derivative1','rot_x_derivative1_power2','rot_x_power2',\n",
    "                             'rot_y','rot_y_derivative1','rot_y_derivative1_power2','rot_y_power2',\n",
    "                             'rot_z','rot_z_derivative1','rot_z_derivative1_power2','rot_z_power2',\n",
    "                             'csf','csf_derivative1','csf_derivative1_power2','csf_power2',\n",
    "                             'white_matter','white_matter_derivative1','white_matter_derivative1_power2','white_matter_power2'\n",
    "                            ]\n",
    "\n",
    "        final_confounds = confound_vars\n",
    "\n",
    "        design_matrices = []\n",
    "\n",
    "        print(\"Creating First Level Design matrix ... \")\n",
    "\n",
    "        for idx, img in enumerate(fmri_imgs):\n",
    "# Build experimental paradigm\n",
    "            run = idx\n",
    "            events,tr,n_scans = load_bids_events(layout,layout_raw, sub, run, sess)\n",
    "    # Define the sampling times for the design matrix\n",
    "            frame_times = np.arange(n_scans) * tr\n",
    "            confound_file = confound_files[run]\n",
    "            confound_df = pd.read_csv(confound_file, delimiter='\\t')\n",
    "            confound_df = confound_df[final_confounds]\n",
    "            confound_df.fillna(0, inplace=True)\n",
    "    # Build design matrix with the previously defined parameters\n",
    "            design_matrix = make_first_level_design_matrix(\n",
    "                frame_times,\n",
    "                events,\n",
    "                hrf_model=hrf_model,\n",
    "                drift_model=\"polynomial\",\n",
    "                drift_order=3,\n",
    "                add_regs=confound_df,\n",
    "                add_reg_names=confound_vars,\n",
    "                high_pass=high_pass,\n",
    "            )\n",
    "            design_matrix = design_matrix.iloc[:,0:11] # taking out constant intercept and adding in an intercept for each individual run\n",
    "# this allows average voxel to vary across runs instead of assuming its constant \n",
    "            if idx == 0:\n",
    "                design_matrix['intercept1'] = 1 \n",
    "                design_matrix['intercept2'] = 0\n",
    "                design_matrix['intercept3'] = 0\n",
    "            elif idx == 1:\n",
    "                design_matrix['intercept1'] = 0\n",
    "                design_matrix['intercept2'] = 1 \n",
    "                design_matrix['intercept3'] = 0\n",
    "            else: \n",
    "                design_matrix['intercept1'] = 0\n",
    "                design_matrix['intercept2'] = 0 \n",
    "                design_matrix['intercept3'] = 1\n",
    "    # put the design matrices in a list\n",
    "            design_matrices.append(design_matrix)\n",
    "    \n",
    "# can visualize the design matrix with the line below \n",
    "#plot_design_matrix(design_matrices[1])\n",
    "        print(\"First Level Design Matrix completed\")\n",
    "\n",
    "        contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "        basic_contrasts = {\n",
    "            column: contrast_matrix[i]\n",
    "            for i, column in enumerate(design_matrix.columns)\n",
    "        }\n",
    "\n",
    "        contrasts = {\n",
    "            \"self-other\": (basic_contrasts[\"self\"] - basic_contrasts[\"other\"]),\n",
    "            \"self-fix\": (basic_contrasts[\"self\"] - basic_contrasts[\"fix\"]),\n",
    "            \"other-fix\": (basic_contrasts[\"other\"] - basic_contrasts[\"fix\"]),\n",
    "            \"case-fix\": (basic_contrasts[\"case\"] - basic_contrasts[\"fix\"]),\n",
    "            \"self-case\": (basic_contrasts[\"self\"] - basic_contrasts[\"case\"])\n",
    "        }\n",
    "\n",
    "        print(\"Fitting first-level GLM ...\")\n",
    "        #added gm mask \n",
    "        fmri_glm = FirstLevelModel(mask_img = icbm_mask)\n",
    "        #no gm mask \n",
    "        #fmri_glm = FirstLevelModel()\n",
    "        \n",
    "        fmri_glm = fmri_glm.fit(fmri_imgs, design_matrices=design_matrices)\n",
    "\n",
    "        print(\"First-level completed!\")\n",
    "\n",
    "        mean_image = mean_img(fmri_imgs[0])\n",
    "\n",
    "        print(\"Subject = \" + sub)\n",
    "\n",
    "    # Iterate on contrasts\n",
    "        for contrast_id, contrast_val in contrasts.items():\n",
    "    #print(f\"\\tcontrast id: {contrast_id}\")\n",
    "    # compute the contrasts\n",
    "            outputs = fmri_glm.compute_contrast(contrast_val, output_type='all')\n",
    "    # plot the contrasts as soon as they're generated\n",
    "    # the display is overlaid on the mean fMRI image\n",
    "    # a threshold of 3.0 is used, more sophisticated choices are possible\n",
    "            fname = \"/Volumes/Seagate Desktop Drive/kdata/results/first_level_results/sub\" + sub + \"_\" + contrast_id + \"_ses\" + sess + \".nii.gz\"\n",
    "            # saving z-scores for plotting purposes  \n",
    "            zname = \"/Volumes/Seagate Desktop Drive/kdata/results/first_level_results/plotting/sub\" + sub + \"_\" + contrast_id + \"_ses\" + sess + \".nii.gz\"\n",
    "            nib.save(outputs['effect_size'], fname)\n",
    "            nib.save(outputs['z_score'], zname)\n",
    "            plotting.plot_glass_brain(\n",
    "                outputs['z_score'],\n",
    "                threshold=p001_unc,\n",
    "                display_mode=\"z\",\n",
    "                title=contrast_id,\n",
    "            )\n",
    "            plotting.show()\n",
    "            file_lists[contrast_id].append(fname)\n",
    "            firstlevel_plots[contrast_id].append(zname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4a5ce-67f0-4d87-b798-f79c68c7994f",
   "metadata": {},
   "source": [
    "## Neural Correlates of Self-focused Attention \n",
    "self-other contrast at pre-treatment baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f369f-7ed9-4bdc-ae5d-d0240b157432",
   "metadata": {},
   "source": [
    "### Self-other @ pre-treatment: all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269fba26-3783-4781-9b14-9c318d2dc5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling all of session1 self-other\n",
    "subject_sessions = {}\n",
    "\n",
    "# Populate the dictionary\n",
    "for file_path in file_lists['self-other']:\n",
    "    base_name = os.path.basename(file_path)\n",
    "    parts = base_name.split('_')\n",
    "    subject = parts[0]\n",
    "    session = parts[-1].split('.')[0]\n",
    "    if subject not in subject_sessions:\n",
    "        subject_sessions[subject] = {}\n",
    "    subject_sessions[subject][session] = file_path\n",
    "\n",
    "# # isolate just self-fix session1 \n",
    "self_v_other_pre = [] \n",
    "selfvother_pre_results = []\n",
    "# # Loop through each subject and perform the extraction\n",
    "for subject, sessions in subject_sessions.items():\n",
    "    if 'ses01' in sessions:\n",
    "#         # Load the NIfTI files\n",
    "        ses01_img = nib.load(sessions['ses01'])\n",
    "        \n",
    "        # Append the result to the list\n",
    "        selfvother_pre_results.append((ses01_img))\n",
    "        output_file = f'{subject}_selfvother_pre.nii.gz'\n",
    "        nib.save(ses01_img, output_file)\n",
    "        self_v_other_pre.append([output_file])\n",
    "        print(f'Appended result for {subject}')\n",
    "    else:\n",
    "        print(f'Subject {subject} does not have ses01 files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c06085-62f9-41d6-9360-d8d777604414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second level design matrix \n",
    "selfvother_sldm = np.ones(len(self_v_other_pre))\n",
    "selfvother_sldm = pd.DataFrame(selfvother_sldm, columns=['selfvother'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abe029-57f0-46b8-96e2-0f855ce73ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import SecondLevelModel \n",
    "second_level_input = selfvother_pre_results\n",
    "second_level_model = SecondLevelModel()\n",
    "# plotting.plot_design_matrix(selfvfix_sldm, rescale=False)\n",
    "# plt.title(\"Second-level Design Matrix\", fontsize=20)\n",
    "# plotting.show()\n",
    "\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "\n",
    "second_level_model = SecondLevelModel(n_jobs=2).fit(second_level_input, design_matrix=selfvother_sldm)\n",
    "contrast_val = [1]\n",
    "outputs = second_level_model.compute_contrast(contrast_val, output_type='all')\n",
    "bkg_img = outputs['stat']\n",
    "stat_img = outputs['stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8735f-cc27-4856-88fe-ebdc8b009e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole brain permutation testing for self-other clusters\n",
    "from nilearn.glm.second_level import non_parametric_inference\n",
    "\n",
    "out_dict_selfvother_pre = non_parametric_inference(\n",
    "    second_level_input,\n",
    "    design_matrix=selfvother_sldm,\n",
    "    second_level_contrast=contrast_val,\n",
    "    n_perm=10000,  # 500 for the sake of time. Ideally, this should be 10,000.\n",
    "    two_sided_test=True,\n",
    "    smoothing_fwhm=8.0,\n",
    "    tfce=True,\n",
    "    # mask=selfvfix_mask,\n",
    "    threshold=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e172a-5f6a-4dde-b8ca-a98f1b67201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your TFCE result NIfTI file (replace 'result_file.nii.gz' with your actual file path)\n",
    "result_img = out_dict_selfvother_pre['tfce'] \n",
    "# Plotting the TFCE map\n",
    "plotting.plot_glass_brain(result_img, threshold=0.001, title='TFCE Results', display_mode='ortho',plot_abs=False,\n",
    "                       colorbar=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "logp_max_tfce_img = out_dict_selfvother_pre['logp_max_tfce']\n",
    "\n",
    "threshold = -np.log10(0.001)  # p<0.001 corrected\n",
    "\n",
    "# Plotting the logp_max_tfce map\n",
    "plotting.plot_glass_brain(logp_max_tfce_img, threshold=threshold, title='Log P Max TFCE', display_mode='ortho',plot_abs=False,\n",
    "                        colorbar=True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b27d3-23af-46fd-bb05-e994d9f46975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster summary table / saving thresholded nifti file \n",
    "\n",
    "from nilearn.reporting import get_clusters_table\n",
    "threshold = -np.log10(0.001)  # p<0.001 corrected\n",
    "\n",
    "logp_max_tfce_img = out_dict_selfvother_pre['logp_max_tfce']\n",
    "\n",
    "table = get_clusters_table(logp_max_tfce_img, threshold, 30)\n",
    "print(table.to_latex())\n",
    "\n",
    "thresh_tfce_img = out_dict_selfvother_pre['logp_max_tfce'].get_fdata()\n",
    "thresh_tfce_img = (thresh_tfce_img >= 3)\n",
    "\n",
    "thresh_tfce_img = Nifti1Image(thresh_tfce_img.astype(int), out_dict_selfvother_pre['logp_max_tfce'].affine, header=out_dict_selfvother_pre['logp_max_tfce'].header)\n",
    "\n",
    "fname = \"/Volumes/Seagate Desktop Drive/kdata/results/ms images/selfvsother_allsubs_binarized.nii.gz\"\n",
    "nib.save(thresh_tfce_img, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c350f64c-5f59-42bd-b9ec-a8d1e18aa268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signed, threshold tfce image \n",
    "\n",
    "thresh_tfce_img = out_dict_selfvother_pre['logp_max_tfce'].get_fdata()\n",
    "threshold_mask = (thresh_tfce_img >= 3)\n",
    "\n",
    "# Extracting t_img data\n",
    "t_img = out_dict_selfvother_pre['tfce'].get_fdata()\n",
    "\n",
    "# Applying the threshold mask to t_img\n",
    "filtered_t_img = np.where(threshold_mask, t_img, 0)  # Use 0 for values that do not surpass the threshold\n",
    "\n",
    "# # Creating a new NIfTI image with the filtered data\n",
    "filtered_t_img_nifti = Nifti1Image(filtered_t_img, \n",
    "                                   out_dict_selfvother_patientsvcontrols_pre['t'].affine, \n",
    "                                   header=out_dict_selfvother_patientsvcontrols_pre['t'].header)\n",
    "# # Plotting the logp_max_tfce map\n",
    "plotting.plot_glass_brain(filtered_t_img_nifti, threshold=0, title='Log P Max TFCE', display_mode='ortho',plot_abs=False,\n",
    "                        colorbar=True)\n",
    "\n",
    "fname = \"/Volumes/Seagate Desktop Drive/kdata/results/ms images/selfvsother_allsubs_tfcevals.nii.gz\"\n",
    "nib.save(filtered_t_img_nifti, fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
